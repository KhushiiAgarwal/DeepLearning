# -*- coding: utf-8 -*-
"""AI_Khushi_Agarwal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uLPFsPrF5ikBJjs5XUQ9N0E-o3vy2-rn
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sn
import sklearn
from sklearn.preprocessing import StandardScaler

df=pd.read_csv("wbc_csv.csv")
df.drop(['id'],axis=1,inplace=True)
df=df.iloc[:,0:31]

print(df.shape)
df.info()
df.describe()

df.isnull().sum()

"""# One Hot Encoding"""

from sklearn.preprocessing import OneHotEncoder
df['diagnosis']=df['diagnosis'].astype('category')
df['diagnosistics']=df['diagnosis'].cat.codes
enc=OneHotEncoder()
enc_df=pd.DataFrame(enc.fit_transform(df[['diagnosistics']]).toarray())

y=df['diagnosis']
x=df.drop(labels=['diagnosis','diagnosistics'], axis=1)

from sklearn import preprocessing
scaler = preprocessing.MinMaxScaler()
scaled_df = scaler.fit_transform(x)
scaled_df = pd.DataFrame(scaled_df)
scaled_df

"""# Variance Threshold & CHI sq"""

from sklearn.feature_selection import VarianceThreshold
var_thres=VarianceThreshold(threshold=0)
var_thres.fit(scaled_df)
x.columns[var_thres.get_support()]

#Variance Threshold
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(scaled_df,y,test_size=0.3,stratify=y,random_state=50)
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
X_train.shape, X_test.shape

var_thres=VarianceThreshold(threshold=0)
var_thres.fit(X_train)
sum(var_thres.get_support())
# Finding non constant features

# constant_columns = [column for column in X_train.columns if column not in X_train.columns[var_thres.get_support()]]
# print(len(constant_columns))

"""# Regression"""

from sklearn import preprocessing
from sklearn import metrics
from sklearn import linear_model
from sklearn.metrics import confusion_matrix, accuracy_score

# Train-test split for 'mean' features
X_train, X_test, y_train, y_test = train_test_split(
    df[['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',
        'smoothness_mean', 'compactness_mean', 'concavity_mean',
        'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']],
    df.diagnosistics, test_size=0.2, random_state=42)

#Mean Regression
reg = linear_model.LinearRegression()
reg.fit(X_train, y_train)

# Assuming X_test has the same features as X_train but possibly in a different order
X_test_reordered = X_test[X_train.columns]

# Predictions for 'mean' features
y_pred_binary_mean = (reg.predict(X_test_reordered) >= 0.5).astype(int)

reg.predict([[13,21.82,87.5,519.8,0.1273,0.1932,0.1859,0.09353,0.235,0.07389]])
#if 0.5> B and if 0.5<  M
#10th row

cm_mean = confusion_matrix(y_test, y_pred_binary_mean)
accuracy_mean = accuracy_score(y_test, y_pred_binary_mean)
print("Confusion Matrix (Mean Features):")
print(cm_mean)
print("Accuracy (Mean Features):", accuracy_mean)

X_train, X_test, y_train, y_test = train_test_split(
    df[['radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',
       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',
       'fractal_dimension_se']],
    df.diagnosistics, test_size=0.2, random_state=42)

reg.fit(X_train, y_train)
y_pred_binary_se = (reg.predict(X_test) >= 0.5).astype(int)

reg.predict([[0.8068,0.9017,5.455,102.6,0.006048,0.01882,0.02741,0.0113,0.01468,0.002801]])
#if 0.5> B and if 0.5<  M
#26th row

cm_se = confusion_matrix(y_test, y_pred_binary_se)
accuracy_se = accuracy_score(y_test, y_pred_binary_se)
print("\nConfusion Matrix (SE Features):")
print(cm_se)
print("Accuracy (SE Features):", accuracy_se)

# Train-test split for 'worst' features
X_train, X_test, y_train, y_test = train_test_split(
    df[['radius_worst', 'texture_worst',
       'perimeter_worst', 'area_worst', 'smoothness_worst',
       'compactness_worst', 'concavity_worst', 'concave points_worst',
       'symmetry_worst', 'fractal_dimension_worst']],
    df.diagnosistics, test_size=0.2, random_state=42)

# Linear Regression for 'worst' features
reg.fit(X_train, y_train)
y_pred_binary_worst = (reg.predict(X_test) >= 0.5).astype(int)

reg.predict([[14.67,23.19,96.08,656.7,0.1089,0.1582,0.105,0.08586,0.2346,0.08025]])
#if 0.5> B and if 0.5<  M
#53rd row

cm_worst = confusion_matrix(y_test, y_pred_binary_worst)
accuracy_worst = accuracy_score(y_test, y_pred_binary_worst)
print("\nConfusion Matrix (Worst Features):")
print(cm_worst)
print("Accuracy (Worst Features):", accuracy_worst)

"""#Logistic Regression

  
"""

from sklearn.metrics import accuracy_score,confusion_matrix
from sklearn.linear_model import LogisticRegression

y.value_counts()

X_train, X_test, y_train, y_test = train_test_split(scaled_df,y,test_size=0.3,stratify=y,random_state=50)

#logistic regression on heart.csv
model=LogisticRegression(max_iter=600)
model.fit(X_train,y_train)
test_data_prediction=model.predict(X_test)

accuracy=accuracy_score(y_test,test_data_prediction)
print(" Accuracy of =",model,'=',accuracy)

input_data=(13.8,15.79,90.43,584.1,0.1007,0.128,0.07789,0.05069,0.1662,0.06566,0.2787,0.6205,1.957,23.35,0.004717,0.02065,0.01759,0.009206,0.0122,0.00313,16.57,20.86,110.3,812.4,0.1411,0.3542,0.2779,0.1383,0.2589,0.103)
input_data_array = np.asarray(input_data)
reshaped = input_data_array.reshape(1, -1)

# Confusion Matrix
cm = confusion_matrix(y_test, test_data_prediction)
print("Confusion Matrix:\n", cm)

import matplotlib.pyplot as plt
import seaborn as sn
plt.figure(figsize=(12,7))
sn.heatmap(cm, annot= True)
plt.xlabel('Predicted')
plt.ylabel('Truth')

"""# KNN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score

import math
math.sqrt(len(y_test))

classifier = KNeighborsClassifier(n_neighbors=11, p=2, metric='euclidean')
# Define the model: Init K-NN

X_train, X_test, y_train, y_test = train_test_split(scaled_df,y,test_size=0.3,stratify=y,random_state=55)

classifier.fit(X_train, y_train)
# Predict the test set results
y_pred = classifier.predict(X_test)
y_pred

# Evaluate Model
cm = confusion_matrix(y_test, y_pred)
print (cm)

#sc = StandardScaler()
#y_train = sc.fit_transform(y_train)
#y_test = sc.transform(y_test)

print(accuracy_score(y_test, y_pred))
#print(f1_score(y_test, y_pred))

plt.figure(figsize=(12,7))
sn.heatmap(cm, annot= True)
plt.xlabel('Predicted')
plt.ylabel('Truth')

"""# SVM"""

from sklearn.svm import SVC

X_train, X_test, y_train, y_test = train_test_split(scaled_df,y,test_size=0.25,stratify=y,random_state=50)

clf_linear = SVC(kernel='linear')
clf_linear.fit(X_train, y_train)
#Check for SVM accuracy
y_pred = clf_linear.predict(X_test)
print(accuracy_score(y_test,y_pred))

cm = confusion_matrix(y_test, y_pred )
print("Confusion Matrix:\n", cm)

plt.figure(figsize=(12,7))
sn.heatmap(cm, annot= True)
plt.xlabel('Predicted')
plt.ylabel('Truth')

"""# DecisionTree


"""

from sklearn import tree
model = tree.DecisionTreeClassifier()

X_train, X_test, y_train, y_test = train_test_split(scaled_df,y,test_size=0.15,stratify=y,random_state=50)

model.fit(X_train, y_train)

# model.score(inputs_n,target)

train_accuracy = model.score(X_train, y_train)
print(f"Training Accuracy: {train_accuracy}")

model.predict([[2,1,0,2,1,0,2,1,0,2,1,0,2,1,0,2,1,0,2,1,0,2,1,0,2,1,0,2,1,0]])

model.predict([[1,1,5,2,1,6,3,1,8,2,1,7,4,1,8,2,1,8,2,7,3,2,1,4,2,1,5,2,1,3]])

y_pred = model.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {test_accuracy}")

cm = confusion_matrix(y_test, y_pred )
print("Confusion Matrix:\n", cm)

# import matplotlib.pyplot as plt
# import seaborn as sn
plt.figure(figsize=(12,7))
sn.heatmap(cm, annot= True)
plt.xlabel('Predicted')
plt.ylabel('Truth')

"""# RandomForest"""

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=20)

X_train, X_test, y_train, y_test = train_test_split(scaled_df,y,test_size=0.25,stratify=y,random_state=42)

model.fit(X_train, y_train)
model.score(X_test, y_test)

y_pred = model.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {test_accuracy}")

conf_matrix = confusion_matrix(y_test, y_pred )
print("Confusion Matrix:\n", conf_matrix)

plt.figure(figsize=(12,7))
sn.heatmap(cm, annot= True)
plt.xlabel('Predicted')
plt.ylabel('Truth')

"""#ANN Artificial Neural Networks"""

import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

X_train, X_test, y_train, y_test = train_test_split(scaled_df, y, test_size=0.15, stratify=y, random_state=26)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Initialising ANN
ann = tf.keras.models.Sequential()

#Adding  Hidden Layer
ann.add(tf.keras.layers.Dense(units=6, activation="relu"))
ann.add(tf.keras.layers.Dense(units=6, activation="relu"))

#Adding Output Layer
ann.add(tf.keras.layers.Dense(units=1,activation="sigmoid"))

ann.compile(optimizer="adam", loss="binary_crossentropy", metrics=['accuracy'])

#Fitting ANN
ann.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1)

ann.evaluate(X_test,y_test,batch_size=32)

test_loss, test_accuracy = ann.evaluate(X_test, y_test, batch_size=32)
print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")

y_pred_probs = ann.predict(X_test)
y_pred = (y_pred_probs > 0.5).astype(int)

test_accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy (using sklearn): {test_accuracy}")

conf_matrix = confusion_matrix(y_test, y_pred )
print("Confusion Matrix:\n", conf_matrix)

# import matplotlib.pyplot as plt
# import seaborn as sn
plt.figure(figsize=(12,7))
sn.heatmap(cm, annot= True)
plt.xlabel('Predicted')
plt.ylabel('Truth')